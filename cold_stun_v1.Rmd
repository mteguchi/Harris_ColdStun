---
title: "Cold stunned marine turtles"
output: html_notebook
---

This document describes statistical analyses of cold stunned marine turtle data from Heather Harris. First load data and see what they look like.

```{r}
rm(list=ls())
source("cold_stun_functions.R")
library(tidyverse)

save.fig <- FALSE #TRUE

dat0 <- read.csv(file = "data/ColdStun_data_June2019.csv", 
                 header = TRUE)  %>%
  rownames_to_column() %>%
  select(-c(Field_ID, Database_ID, NMFS_ID, Other_ID, Location, City, County, Country)) %>%
  mutate(Age = as.factor(toupper(Age)),
         Sex = as.factor(toupper(Sex)),
         Condition = as.factor(toupper(Condition)),
         ID = rowname,
         Species = as.factor(ifelse(Common_Name == "Green sea turtle", "CM",
                                    ifelse(Common_Name == "Loggerhead", "CC", "LO"))),
         Body_Temp_C = Confirmed.body.temp.C,
         Year = Year_Initially_Observed,
         Month = Month_Initially_Observed,
         Day = Day_Initially_Observed,
         Date = as.Date(paste(Year, Month, Day, sep = "-"))) %>%
  select(ID, Age, State, Latitude, Longitude, 
         Sex, Weight_kg, CCL_cm, CCW_cm,
         Body_Temp_C, Date, Species) %>%
  filter(Latitude > 34.45)

summary(dat0)
```

After tweaking data a bit, now we have somewhat cleaned up data. First, look at the stranding locations. This should be the same plot as Figure 1 in Deena's report.

```{r, warning=FALSE, cache=TRUE}

water.color <- "lightblue"
land.color <- "darkgray"
border.color <- "gray20"

E.end <- -112
W.end <- -128
N.end <- 51
S.end <- 32
# coast line data are from here: http://openstreetmapdata.com/data/coastlines or
# https://shoreline.noaa.gov/data/datasheets/medres.html and
# http://datapages.com/gis-map-publishing-program/gis-open-files/global-framework/global-heat-flow-database/shapefiles-list
# https://www12.statcan.gc.ca/census-recensement/2011/geo/bound-limit/bound-limit-2016-eng.cfm

# https://www.ngdc.noaa.gov/mgg/shorelines/shorelines.html f is the full resolution - too big
# h is high resolution - should be good enough. 
all.coast <- sp::spTransform(rgdal::readOGR(dsn = "~/R/Oceans and Maps/gshhg-shp-2.3.7/GSHHS_shp/h",
                                            layer = "GSHHS_h_L1",
                                            verbose = FALSE),
                             sp::CRS("+proj=longlat +datum=WGS84"))

W.coast <- raster::crop(all.coast, raster::extent(c(W.end, E.end, S.end, N.end)))

W.coast.df <- broom::tidy(W.coast) 
#   filter(long < E.end & long > W.end & lat < N.end & lat > S.end)

# coast.line.df <- do.call(rbind, W.coast.df)
# colnames(coast.line.df) <- c('X', 'Y', 'idx')
# coast.line.Sp <- latlon2sp(coast.line.df, center.latlon)

# the following shape file was obttained from here: #https://gis.stackexchange.com/questions/153514/us-mexican-border-data
# note that the USGS link is broken but direct link "here" is available. 
# http://txpub.usgs.gov/BEHI/Data_download/Boundaries_Layers/International_Boundary_shp.zip
US_MX_border <- sp::spTransform(rgdal::readOGR(dsn = "~/R/Oceans and Maps/International_Boundary/shp",
                                               layer = "International_Boundary_Final",
                                               verbose = FALSE),
                                sp::CRS("+proj=longlat +datum=WGS84"))

US_MX_border <- raster::crop(US_MX_border, raster::extent(c(W.end, E.end, 30, 35)))
US_MX_border.df <- broom::tidy(US_MX_border)

# US-Canada border was obtained from here: 
# https://hifld-geoplatform.opendata.arcgis.com/datasets/canada-and-us-border
US_Canada_border <- sp::spTransform(rgdal::readOGR(dsn = "~/R/Oceans and Maps/Canada_and_US_Border",
                                                  layer = "Canada_and_US_Border",
                                                  verbose = FALSE),
                                   sp::CRS("+proj=longlat +datum=WGS84"))

US_Canada_border <- raster::crop(US_Canada_border, raster::extent(c(W.end, E.end, 47, 51)))
US_Canada_border.df <- broom::tidy(US_Canada_border) 

# state borders from here: https://www.census.gov/geo/maps-data/data/cbf/cbf_state.html
state_border <- sp::spTransform(rgdal::readOGR(dsn = "~/R/Oceans and Maps/cb_2017_us_state_500k",
                                                   layer = "cb_2017_us_state_500k",
                                                   verbose = FALSE),
                                    sp::CRS("+proj=longlat +datum=WGS84"))

state_border <- raster::crop(state_border, raster::extent(c(W.end, E.end, 30, 50)))
state_border.df <- broom::tidy(state_border)

p1 <- ggplot() + 
  geom_polygon(data = data.frame(y = c(N.end, S.end, S.end, N.end, N.end),
                                 x = c(W.end, W.end, E.end, E.end, W.end)),
               aes(x = x, y = y),
               fill = water.color,
               alpha = 0.8) + 
  geom_polygon(fill = land.color,
               data = W.coast.df,
               aes(x=long, y=lat, group = id),
               alpha = 0.9) +  
  geom_path(data = US_MX_border.df,
            aes(x = long, y = lat, group = group),
            color = border.color,
            size = 0.5) + 
  geom_path(data = US_Canada_border.df,
            aes(x = long, y = lat, group = group),
            color = border.color,
            size = 0.5) + #coord_map()
  geom_path(data = state_border.df,
            aes(x = long, y = lat, group = group),
            color = border.color,
            size = 0.5) + #coord_map()
  geom_path(data = data.frame(x = c(E.end, E.end), 
                              y = c(S.end, N.end)),
            aes(x = x, y = y),
            color = land.color,
            size = 1.2) +  
  geom_point(data = dat0,
             aes(x = Longitude, 
                 y = Latitude,
                 color = Species),
             size = 2,
             alpha = 0.5)  +
  coord_map() +
  xlim(c(-128, E.end))+
  ylab(expression(paste("Latitude (", degree, "N)"))) +
  xlab(expression(paste("Longitude (", degree, "W)", sep=""))) 
    
if (save.fig)
  ggsave(plot = p1,
         device = "png",
         dpi = 600,
         filename = "figures/stranding_map.png")
p1
```

We may remove those found south of Pt Conception, as Deena did (true?). But for now, keep them all. 

Look at size measurements:

```{r}
p2 <- ggplot(data = dat0) +
  geom_point(aes(x = CCL_cm, y = CCW_cm, color = Species, size = Weight_kg))

if (save.fig)
  ggsave(plot = p2,
         device = "png",
         dpi = 600,
         filename = "figures/CCL_CCW_Mass.png")

p2
```


```{r}
p3 <- ggplot(data = dat0) + 
  geom_point(aes(x = CCL_cm, y = Weight_kg, color = Species, size = CCW_cm))

if (save.fig)
  ggsave(plot = p3,
         device = "png",
         dpi = 600,
         filename = "figures/CCL_Mass_CCW.png")
p3
```

Looks like one loggerhead has incorrect weight... CCL and CCW for that individual is identical! 

```{r}
dat0 %>% filter(Species == "CC")
```

The temperature data in the dataset are not very useful because some of them come from quite far away. We should probably get better data. Wind speed and direction prior to and at the day of stranding should be looked at. 

```{r, cache=TRUE, message=FALSE}
library(sp)
library(ncdf4)

# distances from each stranding within which SST data are extracted. It is measured from the 
# center (stranding location) +/- ds (in km). So, in effect SST is extracted from 2 * ds x 2 * ds
# area. Note they are not that different at the scale of 1 km to 10 km. 

ds <- c(3, 5, 10)
d.n <- length(ds)   # this should match the number of dx's below. 

# Get SST for 1, 5, 10 km around each point. 
latlon <- select(dat0, Latitude, Longitude) %>% 
  transmute(X = Longitude, Y = Latitude,
            BeginX_1 = NA, BeginY_1 = NA, EndX_1 = NA, EndY_1 = NA,
            BeginX_2 = NA, BeginY_2 = NA, EndX_2 = NA, EndY_2 = NA,
            BeginX_3 = NA, BeginY_3 = NA, EndX_3 = NA, EndY_3 = NA) 

UTM <- data.frame(X = NA, Y = NA,
                  BeginX_1 = NA, BeginY_1 = NA, EndX_1 = NA, EndY_1 = NA,
                  BeginX_2 = NA, BeginY_2 = NA, EndX_2 = NA, EndY_2 = NA,
                  BeginX_3 = NA, BeginY_3 = NA, EndX_3 = NA, EndY_3 = NA,
                  zone = NA)

# because the range of latitude is quite large, approximate center is moved along each data point.
# convert all lat/lon pairs to UTM coordinates in the appropriate zone. 
centers.UTM <- vector(mode = "list", length = nrow(latlon))
k <- 1
for (k in 1:nrow(dat0)){
  approx.center <- data.frame(X = -120, Y = dat0[k, "Latitude"])
  sp::coordinates(approx.center) <- c("X", "Y")
  sp::proj4string(approx.center) <- CRS("+proj=longlat +datum=WGS84")
  
  # North of ~ Pt Conception is zone 10, and south of it is zone 11
  zone <- ifelse(dat0[k, "Latitude"] > 34.46, 10, 11)
  
  centers.UTM[[k]] <- spTransform(approx.center,
                            CRS(paste0("+proj=utm +zone=", zone, " ellps=WGS84")))
  
  tmp <- latlon2sp(latlon[k, c("X", "Y")], 
                   center.UTM = centers.UTM[[k]], zone )
  
  UTM[k, ] <- c(tmp@data$newX, tmp@data$newY,
                tmp@data$newX - ds[1], tmp@data$newY - ds[1], 
                tmp@data$newX + ds[1], tmp@data$newY + ds[1],
                tmp@data$newX - ds[2], tmp@data$newY - ds[2], 
                tmp@data$newX + ds[2], tmp@data$newY + ds[2],
                tmp@data$newX - ds[3], tmp@data$newY - ds[3], 
                tmp@data$newX + ds[3], tmp@data$newY + ds[3],
                zone)
  
}

# This loop should go over all dx's (2 each) - Begin and End (X,Y)
k <- k1 <- 1
for (k in 1:(2*d.n)){
  tmp <- data.frame(newX = UTM[, (2*k+1)],
                    newY = UTM[, (2*k+2)])
  for (k1 in 1:nrow(tmp)){
    latlon[k1, (2*k+1):(2*k+2)] <- sp2latlon(tmp[k1,], 
                                             center.UTM = centers.UTM[[k1]], 
                                             zone = UTM[k1, "zone"])@coords[, c("X", "Y")]
    
  }
  
}

latlon$Date <- dat0$Date

sst <- sst_anom <- sst_sd <- sst_lag30d <- sst_anom_30d <- matrix(nrow = nrow(latlon),
                                                                  ncol = d.n)

sst_min <- sst_min_lag30d <- air_temp <- air_temp_30d <- matrix(nrow = nrow(latlon),
                                                                ncol = d.n)

wind <- wind_max <- wind_30d <- wind_max_30d <- matrix(nrow = nrow(latlon),
                                           ncol = 1)
k <- k1 <- 1

# for all rows
for (k in 1:nrow(sst)){
  # wind comes in 0.25 degree resolutions so we just pick one without worrying about other spatial
  # resolutions
  out.file.name.wind <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                               "wind.nc")
  
  out.file.name.wind.30d <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                   "wind_30d.nc")
  
  # for number of distances
  for (k1 in 1:d.n){
    out.file.name <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_sst.nc")
    out.file.name.anom <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_sstanom.nc")
    out.file.name.lag30d<- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_sst_lag30d.nc")
    out.file.name.anom.lag30d <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_sstanom_lag30d.nc")
    out.file.name.air.temp<- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_airtemp.nc")
    out.file.name.air.temp.lag30d <- paste0("data/ncfiles/turtle_", dat0[k, "ID"], "_",
                                             ds[k1], "km_airtemp_lag30d.nc")
    
    xlim <- c(latlon[k, (4*k1 - 1)],
              latlon[k, (4*k1 + 1)])
    ylim <- c(latlon[k, (4*k1)],
              latlon[k, (4*k1 + 2)])
    #tlim <- c(latlon[k, "Date"] - 7,
    #          latlon[k, "Date"] + 7)
    
    if(!file.exists(out.file.name)){
      
      # Multi-scale Ultra-high resolution (MUR) SST analysis fv04.1, Monthly
      sstURL <- paste0("https://upwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.nc?sst[(", 
                       latlon[k, "Date"], "T00:00:00Z):1:(", 
                       latlon[k, "Date"], "T00:00:00Z)][(", 
                       signif(ylim[1], digits = 4), "):1:(", 
                       signif(ylim[2], digits = 4), ")][(", 
                       signif(xlim[1], digits = 5), "):1:(", 
                       signif(xlim[2], digits = 5), ")]")

      # Aqua MODIS, NPP, 4km, Daytime 2003-present (8 day composite)
      # sstURL <- paste0("https://upwell.pfeg.noaa.gov/erddap/griddap/erdMH1sstd8day.nc?sst[(", 
      #                  latlon[k, "Date"], "T00:00:00Z):1:(", latlon[k, "Date"], ")][(", 
      #                  ylim[2], "):1:(", ylim[1], "][(", 
      #                  xlim[1], "):1:(", xlim[2], ")]")

      test <- download.file(sstURL,
                            destfile = out.file.name,
                            mode='wb')
      
    }
    
    datafileID <- nc_open(out.file.name)
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01',tz= "GMT")  # true? check with nc files (5/30/2019)
    mat <- ncvar_get(datafileID, varid = 'sst')
    nc_close(datafileID)
    
    sst[k, k1] <- mean(mat, na.rm = T)
    sst_sd[k, k1] <- sqrt(var(as.vector(mat), na.rm = T))
    sst_min[k, k1] <- min(mat, na.rm = T)
    
    if (!file.exists(out.file.name.anom)){
      # Multi-scale Ultra-high resolution (MUR) SST analysis anomaly fv04.1, Monthly
      sstanomURL <- paste0("https://upwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41anommday.nc?sstAnom[(",
                           latlon[k, "Date"], "T00:00:00Z):1:(", 
                           latlon[k, "Date"], "T00:00:00Z)][(", 
                           signif(ylim[1], 4), "):1:(", 
                           signif(ylim[2], 4), ")][(", 
                           signif(xlim[1], 5), "):1:(", 
                           signif(xlim[2], 5), ")]")
      test <- download.file(sstanomURL,
                            destfile = out.file.name.anom,
                            mode='wb')
      
    }

    datafileID <- nc_open(out.file.name.anom)
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01',tz= "GMT")  # true? check with nc files (5/30/2019)
    mat <- ncvar_get(datafileID, varid = 'sstAnom')
    nc_close(datafileID)
    
    sst_anom[k, k1] <- mean(mat, na.rm = T)
    
    if (!file.exists(out.file.name.lag30d)){
      # Multi-scale Ultra-high resolution (MUR) SST analysis anomaly fv04.1, Monthly
      sst30dURL <- paste0("https://upwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41mday.nc?sst[(", 
                          (latlon[k, "Date"] - 29), "T00:00:00Z):1:(", 
                          (latlon[k, "Date"] - 29), "T00:00:00Z)][(", 
                          signif(ylim[1], 4), "):1:(", 
                          signif(ylim[2], 4), ")][(", 
                          signif(xlim[1], 5), "):1:(", 
                          signif(xlim[2], 5), ")]")

      test <- download.file(sst30dURL,
                            destfile = out.file.name.lag30d,
                            mode='wb')
      
    }
    
    datafileID <- nc_open(out.file.name.lag30d)
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01',tz= "GMT")  
    mat <- ncvar_get(datafileID, varid = 'sst')
    nc_close(datafileID)
    
    sst_lag30d[k, k1] <- mean(mat, na.rm = T)
    sst_min_lag30d[k, k1] <- min(mat, na.rm = T)
  
    if (!file.exists(out.file.name.anom.lag30d)){
      # Multi-scale Ultra-high resolution (MUR) SST analysis anomaly fv04.1, Monthly
      sstanomURL <- paste0("https://upwell.pfeg.noaa.gov/erddap/griddap/jplMURSST41anommday.nc?sstAnom[(",
                           (latlon[k, "Date"] - 29), "T00:00:00Z):1:(", 
                           (latlon[k, "Date"] - 29), "T00:00:00Z)][(", 
                           signif(ylim[1], 4), "):1:(", signif(ylim[2], 4), ")][(", 
                           signif(xlim[1], 5), "):1:(", signif(xlim[2], 5), ")]")
      test <- download.file(sstanomURL,
                            destfile = out.file.name.anom.lag30d,
                            mode='wb')
      
    }

    datafileID <- nc_open(out.file.name.anom.lag30d)
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01',tz= "GMT")  
    mat <- ncvar_get(datafileID, varid = 'sstAnom')
    nc_close(datafileID)
    
    sst_anom_30d[k, k1] <- mean(mat, na.rm = T)
    
    # havent' found good airtemp dataset yet.
    # if (!file.exists(out.file.name.air.temp)){
    #   # NOAA NOS SOS, Experimental, 1853-present, Air temperature
    #   # (https://coastwatch.pfeg.noaa.gov/erddap/tabledap/nosSosATemp.html)
    #   airtempURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/tabledap/nosSosATemp.nc?longitude%2Clatitude%2Ctime%2Cair_temperature%2Cquality_flags&longitude%3E=", 
    #                        xlim[1], "&longitude%3C=", xlim[2], 
    #                        "&latitude%3E=", ylim[1], "&latitude%3C=", ylim[2], 
    #                        "&time%3E=", latlon[k, "Date"], 
    #                        "T00%3A00%3A00Z&time%3C=", latlon[k, "Date"], "T00%3A00%3A00Z")
    #   
    #   test <- download.file(airtempURL,
    #                         destfile = out.file.name.air.temp,
    #                         mode='wb')
    #   
    #   datafileID <- nc_open(out.file.name.air.temp)
    #   lon <- ncvar_get(datafileID, varid="longitude")
    #   lat <- ncvar_get(datafileID, varid="latitude")
    #   time <- ncvar_get(datafileID, varid="time")
    #   time <- as.POSIXlt(time, origin='1970-01-01',tz= "GMT")  
    #   mat <- ncvar_get(datafileID, varid = '')
    #   nc_close(datafileID)
    #   
    #   air_temp[k, k1] <- mean(mat, na.rm = T)
    #   
    #   
    # }
    
    
  }
  if (!file.exists(out.file.name.wind)){
    # wind speed and direction data end at 2018-10-09: 
    
    # NOAA/NCDC blended daily global 0.25-degree sea surface winds, 1987-2011, Lon +/-180 
    # (https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOwDly_LonPM180.html)
    
    #longitude needs to be increments of 0.25 degrees:
    # because we are always in the negative longitude values...
    cut.off.lon <- c(0.75, 0.5, 0.25, 0)
    dif.lon <- abs(trunc(latlon[k, "X"]) - cut.off.lon - latlon[k, "X"])
    X.cut.off <- trunc(latlon[k, "X"]) - cut.off.lon[dif.lon == min(dif.lon)]
    X.min <- ifelse(X.cut.off >= latlon[k, "X"], X.cut.off - 0.25, X.cut.off)
    X.max <- X.min + 0.25
    
    # and latitude is always positive in our case
    cut.off.lat <- c(0, 0.25, 0.5, 0.75)
    dif.lat <- abs(latlon[k, "Y"] - cut.off.lat - latlon[k, "Y"])
    Y.cut.off <- trunc(latlon[k, "Y"]) - cut.off.lat[dif.lat == min(dif.lat)]
    Y.min <- ifelse(Y.cut.off >= latlon[k, "Y"], Y.cut.off - 0.25, Y.cut.off)
    Y.max <- Y.min + 0.25
    
    if (lubridate::year(latlon[k, "Date"]) < 2011){
      var.name <- "ncdcOwDly"
    } else {
      var.name <-"ncdcOwDlyP" 
       
    }

    if (latlon[k, "Date"] < as.Date("2018-10-10")){
      windURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/griddap/", var.name, "_LonPM180.nc?u[(",
                        latlon[k, "Date"], "T09:00:00Z):1:(", latlon[k, "Date"],
                        "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", Y.max, ")][(", 
                        X.min, "):1:(", X.max, ")],v[(", latlon[k, "Date"], "T09:00:00Z):1:(", 
                        latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", 
                        Y.max, ")][(", X.min, "):1:(", X.max, ")],w[(", latlon[k, "Date"],
                        "T09:00:00Z):1:(", latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", 
                        Y.min, "):1:(", Y.max, ")][(", X.min, "):1:(", X.max, ")]")
      
      test <- download.file(windURL,
                            destfile = out.file.name.wind,
                            mode='wb')
  
    }
  }  

  if (latlon[k, "Date"] < as.Date("2018-10-10")){
    datafileID <- nc_open(out.file.name.wind)
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01', tz= "GMT")  
    u <- ncvar_get(datafileID, varid = "u")
    v <- ncvar_get(datafileID, varid = "v")
    w <- ncvar_get(datafileID, varid = "w")
    
    nc_close(datafileID)
  } else {
    U <- v <- w <- NA
  }
  wind[k, 1] <- mean(w, na.rm = T)
  wind_max[k, 1] <- max(w, na.rm = T)
  #wind_u[k, 1] <- mean(u, na.rm = T)
  #wind_v[k, 1] <- mean(v, na.rm = T)
  
  
  if (!file.exists(out.file.name.wind.30d)){
    # wind speed and direction data end at 2018-10-09: 
    
    # NOAA/NCDC blended daily global 0.25-degree sea surface winds, 1987-2011, Lon +/-180 
    # (https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOwDly_LonPM180.html)
    
    #longitude needs to be increments of 0.25 degrees:
    # because we are always in the negative longitude values...
    cut.off.lon <- c(0.75, 0.5, 0.25, 0)
    dif.lon <- abs(trunc(latlon[k, "X"]) - cut.off.lon - latlon[k, "X"])
    X.cut.off <- trunc(latlon[k, "X"]) - cut.off.lon[dif.lon == min(dif.lon)]
    X.min <- ifelse(X.cut.off >= latlon[k, "X"], X.cut.off - 0.25, X.cut.off)
    X.max <- X.min + 0.25
    
    # and latitude is always positive in our case
    cut.off.lat <- c(0, 0.25, 0.5, 0.75)
    dif.lat <- abs(latlon[k, "Y"] - cut.off.lat - latlon[k, "Y"])
    Y.cut.off <- trunc(latlon[k, "Y"]) - cut.off.lat[dif.lat == min(dif.lat)]
    Y.min <- ifelse(Y.cut.off >= latlon[k, "Y"], Y.cut.off - 0.25, Y.cut.off)
    Y.max <- Y.min + 0.25
    
    if (latlon[k, "Date"] < as.Date("2011-10-01")){
      var.name <- "ncdcOwDly" # to 2011-09-30
      windURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/griddap/", var.name, "_LonPM180.nc?u[(",
                        latlon[k, "Date"]-29, "T09:00:00Z):1:(", latlon[k, "Date"],
                        "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", Y.max, ")][(", 
                        X.min, "):1:(", X.max, ")],v[(", latlon[k, "Date"]-29, "T09:00:00Z):1:(", 
                        latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", 
                        Y.max, ")][(", X.min, "):1:(", X.max, ")],w[(", latlon[k, "Date"]-29,
                        "T09:00:00Z):1:(", latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", 
                        Y.min, "):1:(", Y.max, ")][(", X.min, "):1:(", X.max, ")]")
      
      test <- download.file(windURL,
                            destfile = out.file.name.wind.30d,
                            mode='wb')
    } else {
      var.name <-"ncdcOwDlyP" # from 2011-10-01
      if((latlon[k, "Date"] - 30) < as.Date("2011-10-01")){
        var.name.2 <- "ncdcOwDly"
        windURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/griddap/", var.name.2,
                          "_LonPM180.nc?u[(",
                          latlon[k, "Date"]-29, 
                          "T09:00:00Z):1:(2011-09-30T09:00:00Z)][(10.0):1:(10.0)][(",
                          Y.min, "):1:(", Y.max, ")][(", 
                          X.min, "):1:(", X.max, ")],v[(", latlon[k, "Date"]-29,
                          "T09:00:00Z):1:(2011-09-30T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", 
                          Y.max, ")][(", X.min, "):1:(", X.max, ")],w[(", latlon[k, "Date"]-29,
                          "T09:00:00Z):1:(2011-09-30T09:00:00Z)][(10.0):1:(10.0)][(", 
                          Y.min, "):1:(", Y.max, ")][(", X.min, "):1:(", X.max, ")]")
        
        test <- download.file(windURL,
                              destfile = paste0(unlist(out.file.name.wind.30d, "\\.nc"), "_dat1.nc"),
                              mode='wb')
        
        windURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/griddap/", var.name, 
                          "_LonPM180.nc?u[(2011-10-01T09:00:00Z):1:(", latlon[k, "Date"],
                          "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", Y.max, ")][(", 
                          X.min, "):1:(", X.max, ")],v[(2011-10-01T09:00:00Z):1:(", 
                          latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", 
                          Y.max, ")][(", X.min, "):1:(", X.max, ")],w[(2011-10-01T09:00:00Z):1:(",
                          latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", 
                          Y.min, "):1:(", Y.max, ")][(", X.min, "):1:(", X.max, ")]")
        
        test <- download.file(windURL,
                              destfile = out.file.name.wind.30d,
                              mode='wb')
      } else {
        if (latlon[k, "Date"] < as.Date("2018-10-10")){
          
          windURL <- paste0("https://coastwatch.pfeg.noaa.gov/erddap/griddap/", var.name,
                            "_LonPM180.nc?u[(",
                            latlon[k, "Date"]-29, "T09:00:00Z):1:(", latlon[k, "Date"],
                            "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", Y.max, ")][(", 
                            X.min, "):1:(", X.max, ")],v[(", latlon[k, "Date"]-29, "T09:00:00Z):1:(", 
                            latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", Y.min, "):1:(", 
                            Y.max, ")][(", X.min, "):1:(", X.max, ")],w[(", latlon[k, "Date"]-29,
                            "T09:00:00Z):1:(", latlon[k, "Date"], "T09:00:00Z)][(10.0):1:(10.0)][(", 
                            Y.min, "):1:(", Y.max, ")][(", X.min, "):1:(", X.max, ")]")
          
          test <- download.file(windURL,
                                destfile = out.file.name.wind.30d,
                                mode='wb')
        }
      }
      
      
    }
  }
    
  if (((latlon[k, "Date"] > as.Date("2011-09-30")) & 
       (latlon[k, "Date"] - 30) < as.Date("2011-10-01"))){
    
    datafileID <- nc_open(out.file.name.wind.30d)
    datafileID2 <- nc_open(paste0(unlist(out.file.name.wind.30d, "\\.nc"), "_dat1.nc"))
    
    lon <- ncvar_get(datafileID, varid="longitude")
    lat <- ncvar_get(datafileID, varid="latitude")
    time <- ncvar_get(datafileID, varid="time")
    time <- as.POSIXlt(time, origin='1970-01-01', tz= "GMT")  
    u <- ncvar_get(datafileID, varid = "u")
    v <- ncvar_get(datafileID, varid = "v")
    w <- ncvar_get(datafileID, varid = "w")
    
    lon2 <- ncvar_get(datafileID2, varid="longitude")
    lat2 <- ncvar_get(datafileID2, varid="latitude")
    time2 <- ncvar_get(datafileID2, varid="time")
    time2 <- as.POSIXlt(time2, origin='1970-01-01', tz= "GMT")  
    u2 <- ncvar_get(datafileID2, varid = "u")
    v2 <- ncvar_get(datafileID2, varid = "v")
    w2 <- ncvar_get(datafileID2, varid = "w")
    
    nc_close(datafileID)
    nc_close(datafileID2)
    
    u <- abind::abind(u, u2)
    v <- abind::abind(v, v2)
    w <- abind::abind(w, w2)
    
  } else {
    if (latlon[k, "Date"] < as.Date("2018-10-10")){
      datafileID <- nc_open(out.file.name.wind.30d)
      lon <- ncvar_get(datafileID, varid="longitude")
      lat <- ncvar_get(datafileID, varid="latitude")
      time <- ncvar_get(datafileID, varid="time")
      time <- as.POSIXlt(time, origin='1970-01-01', tz= "GMT")  
      u <- ncvar_get(datafileID, varid = "u")
      v <- ncvar_get(datafileID, varid = "v")
      w <- ncvar_get(datafileID, varid = "w")
      
      nc_close(datafileID)
    } else {
      w <- u <- v <- NA
    }
  }
  
  wind_30d[k, 1] <- mean(w, na.rm = T)
  wind_max_30d[k, 1] <- max(w, na.rm = T)
  #wind_u_30d[k, 1] <- mean(u, na.rm = T)
  #wind_v_30d[k, 1] <- mean(v, na.rm = T)
}


```

We also need the background temperature data for the time period?

Change in body size over time?
```{r}
p <- ggplot(data = dat0) + 
  geom_point(aes(x = Date, y = CCL_cm, color = Species, size = Latitude))

if (save.fig)
    ggsave(plot = p,
         device = "png",
         dpi = 600,
         filename = "figures/date_CCL_latitude.png")

p
```


Once data are downloaded, combine it with the original dataset.  CCL was not measured for 3 with body temperature... kinda odd? Only ridleys are available... 

```{r}
sst.df <- data.frame(sst)
colnames(sst.df) <- c("SST_1", "SST_2", "SST_3")

sst.anom.df <- data.frame(sst_anom)
colnames(sst.anom.df) <- c("SST_1_ANOM", "SST_2_ANOM", "SST_3_ANOM")

sst.sd.df <- data.frame(sst_sd)
colnames(sst.sd.df) <- c("SST_1_SD", "SST_2_SD", "SST_3_SD")

sst.min.df <- data.frame(sst_min)
colnames(sst.min.df) <- c("SST_1_min", "SST_2_min", "SST_3_min")

sst.lag30d.df <- data.frame(sst_lag30d)
colnames(sst.lag30d.df) <- c("SST_1_lag30", "SST_2_lag30", "SST_3_lag30")

sst.min.lag30d.df <- data.frame(sst_min_lag30d)
colnames(sst.lag30d.df) <- c("SST_1_min_lag30", "SST_2_min_lag30", "SST_3_min_lag30")

sst.anom.lag30d.df <- data.frame(sst_anom_30d)
colnames(sst.anom.lag30d.df) <- c("SST_1_ANOM_lag30", "SST_2_ANOM_lag30", "SST_3_ANOM_lag30")

wind.df <- data.frame(wind)

dat1 <- cbind(dat0, 
              sst.df, 
              sst.min.df, 
              sst.anom.df, 
              sst.lag30d.df, 
              sst.min.lag30d.df, 
              sst.sd.df, 
              sst.anom.lag30d.df) %>%
  mutate(SST_1_CV = SST_1_SD/SST_1,
         SST_2_CV = SST_2_SD/SST_2,
         SST_3_CV = SST_3_SD/SST_3)

p4 <- ggplot(data = dat1) + 
  geom_point(aes(x = SST_1_min, 
                 y = Body_Temp_C, 
                 size = CCL_cm)) +
  xlim(c(9, 12))

if (save.fig)
  ggsave(plot = p4,
         device = "png",
         dpi = 600,
         filename = "figures/SST1_min_BodyTemp.png")

p4
```

```{r}

p5 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_3_min, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p5,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST3_min.png")

p5
```

```{r}
p6 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_3_ANOM, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p6,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST3anom.png")

p6
```


```{r}
p7 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_3_CV, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p7,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST3cv.png")

p7
```


```{r}
p9 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_3_min_lag30, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p9,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST3_min_lag30.png")

p9

```



```{r}
p8 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_3_ANOM_lag30, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p8,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST3anom_lag30.png")

p8
```


```{r}
p10 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_2_min_lag30, 
                 color = Species),
             size = 3)


if (save.fig)
  ggsave(plot = p10,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST2_min_lag30.png")


p10
```



```{r}
p11 <- ggplot(data = dat1) + 
  geom_point(aes(x = Date, 
                 y = SST_2_ANOM_lag30, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p11,
         device = "png",
         dpi = 600,
         filename = "figures/date_SST2anom_lag30.png")

p11
```

It seems like 2015 was a quite different year from all others - the reasons for these observed strandings for 2015 might have been different from others. So, to incorporate the climate effect, I downloaded El Nino index from here (https://www.esrl.noaa.gov/psd/enso/mei/). The data file consists of two-month values for each year, starting in 1979.  The current version (as of June 5, 2019) includes 2019 March/April.  Raw data file (meiv2_20190605.txt) was manipulated to remove lines that describe the datafile, rather than providing actual index values.  The new file is named meiv2_notext_20190605.txt. Missing values for the remainder of 2019 are indicated by -999.00. 

```{r}
library(data.table)
MEI.v2 <- fread(file = "data/meiv2_notext_20190605.txt")
colnames(MEI.v2) <- c("Year", "DJ", "JF", "FM", "MA", "AM", 
                      "MJ", "JJ", "JA", "AS", "SO", "ON", "ND") 
MEI.v2[MEI.v2==-999] <- NA

MEI.v2.long <- melt(MEI.v2, 
                    id.vars = "Year", 
                    value.name = "MEI.v2",
                    variable.name = "period")

month <- vector(mode = "numeric", length = nrow(MEI.v2.long))

month[MEI.v2.long$period == "DJ"] <- 1
month[MEI.v2.long$period == "JF"] <- 2
month[MEI.v2.long$period == "FM"] <- 3
month[MEI.v2.long$period == "MA"] <- 4
month[MEI.v2.long$period == "AM"] <- 5
month[MEI.v2.long$period == "MJ"] <- 6
month[MEI.v2.long$period == "JJ"] <- 7
month[MEI.v2.long$period == "JA"] <- 8
month[MEI.v2.long$period == "AS"] <- 9
month[MEI.v2.long$period == "SO"] <- 10
month[MEI.v2.long$period == "ON"] <- 11
month[MEI.v2.long$period == "ND"] <- 12

MEI.v2.long$month <- month
MEI.v2.long$year.month.num <- MEI.v2.long$Year + MEI.v2.long$month/12

MEI.v2.long <- arrange(MEI.v2.long, Year)

MEI.v2.lag1yr.long <- cbind(Year = MEI.v2.long$Year[13:nrow(MEI.v2.long)],
                            MEI.v2.long[1:(nrow(MEI.v2.long)-12), 2:ncol(MEI.v2.long)])

MEI.v2.lag6mo.long <- cbind(Year = MEI.v2.long$Year[7:nrow(MEI.v2.long)],
                            MEI.v2.long[1:(nrow(MEI.v2.long)-6), 2:ncol(MEI.v2.long)])

MEI.v2.long %>% 
  mutate(year.month = paste(Year, month, sep = ".")) -> MEI.v2.long

MEI.v2.lag1yr.long %>% 
  mutate(year.month = paste(Year, month, sep = ".")) %>%
  rename(MEI.v2.lag1yr = MEI.v2) -> MEI.v2.lag1yr.long

MEI.v2.lag6mo.long %>% 
  mutate(year.month = paste(Year, month, sep = ".")) %>%
  rename(MEI.v2.lag6mo = MEI.v2) -> MEI.v2.lag6mo.long

dat1 %>% mutate(year.month = paste(lubridate::year(Date),
                                   lubridate::month(Date),
                                   sep = ".")) -> dat1

dat1.MEI <- left_join(dat1, MEI.v2.long, by = "year.month")
dat1.MEI.lag1yr <- left_join(dat1, MEI.v2.lag1yr.long, by = "year.month")
dat1.MEI.lag6mo <- left_join(dat1, MEI.v2.lag6mo.long, by = "year.month")
```

How does the MEI values play a role in strandings?

```{r}
p12 <- ggplot(data = dat1.MEI) + 
  geom_point(aes(x = Date, 
                 y = MEI.v2, 
                 color = Species),
             size = 3)

if (save.fig)
  ggsave(plot = p12,
         device = "png",
         dpi = 600,
         filename = "figures/date_MEIv2.png")

p12
```

So, the strandings during 2015 and early 2016 might have been affected by positive MEI values - possibly in the northern region?  Next plot adds latitude to this plot and size information is dropped.

```{r}
p13 <- ggplot(data = dat1.MEI) + 
  geom_point(aes(x = Date, 
                 y = MEI.v2, 
                 color = Species, 
                 size = Latitude))

if (save.fig)
  ggsave(plot = p13,
         device = "png",
         dpi = 600,
         filename = "figures/date_MEIv2_latitude.png")

p13

```

What if we lag MEI by 6 months or 1 year?

```{r}

p14 <- ggplot(data = dat1.MEI.lag1yr) + 
  geom_point(aes(x = Date, 
                 y = MEI.v2.lag1yr, 
                 color = Species, 
                 size = Latitude))

if (save.fig)
  ggsave(plot = p14,
         device = "png",
         dpi = 600,
         filename = "figures/date_MEIv2lag1yr_latitude.png")

p14
```

```{r}

p15 <- ggplot(data = dat1.MEI.lag6mo) + 
  geom_point(aes(x = Date, 
                 y = MEI.v2.lag6mo, 
                 color = Species, 
                 size = Latitude))

if (save.fig)
  ggsave(plot = p15,
         device = "png",
         dpi = 600,
         filename = "figures/date_MEIv2lag6mo_latitude.png")

p15
```

How did the MEI change over time?

```{r}
ggplot() + 
  geom_point(data = filter(MEI.v2.lag1yr.long, 
                           Year > 2009),
             aes(x = year.month.num,
                 y = MEI.v2.lag1yr)) + 
  geom_point(data = dat1.MEI,
             aes(x = year.month.num,
                 y = 0,
                 color = Species),
             size = 3)
```

# strandings per year? 

```{r}
dat1.MEI %>% filter(Year > 2009) %>%
  group_by(Year) %>%
  summarise(mean.MEI = mean(MEI.v2),
         n = n()) -> dat1.MEI.byYr

ggplot(dat1.MEI.byYr) + 
  geom_point(aes(x = mean.MEI, y = n, color = Year), size = 3)
```


```{r}
dat1.MEI.lag1yr %>% 
  filter(Year > 2009) %>%
  group_by(Year) %>%
  summarise(mean.MEI.lag1yr = mean(MEI.v2.lag1yr),
         n = n()) -> dat1.MEI.lag1yr.byYr

ggplot(dat1.MEI.lag1yr.byYr) + 
  geom_point(aes(x = mean.MEI.lag1yr, y = n, color = Year), size = 3)
```


```{r}
dat1.MEI.lag6mo %>% 
  filter(Year > 2009) %>%
  group_by(Year) %>%
  summarise(mean.MEI.lag6mo = mean(MEI.v2.lag6mo),
         n = n()) -> dat1.MEI.lag6mo.byYr

ggplot(dat1.MEI.lag6mo.byYr) + 
  geom_point(aes(x = mean.MEI.lag6mo, y = n, color = Year), size = 3)
```

